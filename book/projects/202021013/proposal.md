# Project Title

_Prepared by: 김지연_

1. 김지연 202021013

## Table of Contents

- [Project Title](#project-title)
  - [Table of Contents](#table-of-contents)
  - [1. Executive Summary](#1-executive-summary)
  - [2. Background](#2-background)
  - [3. Objectives](#3-objectives)
  - [4. Scope](#4-scope)
  - [5. Software Process Model](#5-software-process-model)
  - [6. Budget](#6-budget)
  - [7. System Architecture](#7-system-architecture)
  - [8. Risks Assessment](#8-risks-assessment)
  - [9. Resources](#9-resources)
  - [10. Technical Specifications](#10-technical-specifications)
  - [11. Timeline and Deliverables](#11-timeline-and-deliverables)
  - [12. Conclusion](#12-conclusion)


## 1. Executive Summary

- 시대에 맞춘 오타 수정 시스템의 주요 목표는 현재 트랜드에 적응하여 오타를 감지하고 수정하는 능력을 가진 AI 시스템을 개발하는 것으로 이를 통해 시대에 따라 언어와 텍스트 스타일이 변화하는 문제를 해결하고 올바른 정보 전달을 지원하여 사용자 경험을 개선하고자 합니다.

## 2. Background

- 현대 사회에서 텍스트는 중요한 의사소통 도구이며, 온라인 플랫폼과 소셜 미디어의 보급으로 텍스트 사용량이 폭증했습니다. 기존의 오타 교정 시스템은 과거 데이터에 의존하여 현대 언어와 문체에 부적응을 초래할 수 있습니다. 따라서 현대 텍스트의 품질을 향상시키기 위해, 현대 언어와 문체에 대응하는 오타 교정 시스템을 개발하고자 합니다. 이로써 올바른 정보 전달과 소통의 효율성을 높이며 사용자 경험을 향상시키며 현대의 급격한 언어 변화와 텍스트 사용량 증가에 대응하기 위해 선택되었습니다.

## 3. Objectives

- 2023년 12월 10일 까지 LLM 모델을 활용 하여 2000년 대 초반과 현재의 유행어와 신조어를 고려한 오타 수정 시스템을 개발 하여 2000년대 초반과 현재를 비교하여 프로젝트를 진행할 것입니다. 오타 수정 시스템의 정확도를 측정하여 2000년대 초반과 현재의 텍스트에서 발견된 오타의 수를 비교합니다.  LLM 모델을 활용하여 오타 수정 시스템을 개발하기 위해 필요한 인력 및 컴퓨팅 자원을 확보합니다. 또한, 이 프로젝트는 딥러닝 자연어처리 과목과 밀접한 관련이 있어, 해당 과목의 학습과 실무 경험을 향상시키는데 기여할 것으로 예상됩니다.

## 4. Scope

- Define the scope of the project, outlining its features and functionalities.
- Mention any limitations or constraints such as resources, time, or technologies.

## 5. Software Process Model

V 모델은 소프트웨어 개발 및 품질 관리 단계를 나타내는 대칭적인 모델로, 개발과 품질 보증 단계가 대칭되어 연결되어 있습니다.

1. 요구사항 분석 (Requirements Analysis):
2010년 이전의 인터넷 플랫폼(싸이월드)에서 크롤링한 데이터와 유튜브 채널 및 댓글 데이터를 수집하여 당시의 맞춤법 오류 및 오타 패턴을 파악하고, 현재의 유튜브와 인스타그램 댓글 데이터를 크롤링하여 이를 오타 수정 시스템에 적용하여 신조어와 유행어를 오타가 아닌 올바른 단어로 자동으로 수정하도록 하는 것을 목표로 합니다.
2. 시스템 설계 (System Design):
    
    데이터 수집과 분석:
    
    - 2010년 데이터 수집: 2010년 이전의 인터넷(싸이월드) 크롤링 및 유튜브 채널 및 댓글 데이터를 수집하여 당시의 맞춤법 오류 및 오타 패턴을 파악합니다.
    현재 데이터 수집 : 유튜브 댓글과 인스타 게시물 및 댓글을 크롤링을 통해 데이터를 수집합니다.
    - 수집한 데이터를 자연어 처리 및 텍스트 분석 기술을 사용하여 토픽 모델링, 언어 패턴 인식, 형태소 분석 등을 통해 유행어와 신조어를 식별하고 분류합니다.
    
    데이터 전처리:
    
    - 수집한 데이터를 정제하고 표준화 합니다. 중복 데이터나 불필요한 정보를 제거하고, 텍스트를 토큰화 하여 처리 가능한 형태로 변환합니다.
    - 토큰화, 불용어 제거, 형태소 분석을 진행합니다. 형태소 분석과 같은 언어 처리 기술을 사용하여 텍스트를 분해하고, 언어 특성을 고려하여 텍스트를 정규화 합니다.
    
    유행어 및 신조어 식별:
    
    - 소셜 미디어 플랫폼에서 빈번하게 사용되는 특정 어휘나 해시태그를 감지하고, 이를 유행어로 분류합니다.
    
    간트 차트:
    
    - 데이터 수집: 4주
    - 데이터 전처리 및 분석: 2주
3. 모델 통합 및 개발 (Model Integration and Development):
LLM 모델을 개발하고 학습시킵니다. 이 모델은 과거와 현재의 언어 트렌드를 반영하도록 훈련되어야 합니다.
신조어 및 유행어 감지 및 수정 알고리즘을 개발하고 모델과 통합합니다.
네이버 맞춤법 검사기 라이브러리 py-hanspell을 참고하고자 합니다. - https://github.com/ssut/py-hanspell
    
    간트 차트:
    
    - 모델 개발: 2주
    - 시스템 구현: 2주
4. 테스트 계획 (Test Planning):
각 시대별 데이터와 시스템에 대한 테스트 계획을 수립합니다. 과거와 현재의 언어 트렌드에 따라 테스트 데이터를 선정합니다.
5. 단위 테스트 (Unit Testing):
각 시대별로 개발한 모델과 시스템의 단위 테스트를 진행하여 정확성을 확인합니다.
6. 통합 및 시스템 테스트 (Integration and System Testing):
각 시대별로 시스템의 통합 테스트를 수행하고, 오타 수정 및 유행어 감지 기능이 요구사항을 충족하는지 확인합니다.
7. 검증 및 확인 (Verification and Validation):
검증 단계에서는 시스템이 요구사항을 충족하는지 검증합니다. 확인 단계에서는 사용자의 요구사항을 검토하고 피드백을 수용하여 개선합니다.
    
    간트 차트:
    
    - 성능 평가 및 오류 수정: 1주
    - 사용자 피드백 및 모델 업데이트 계획: 1주
8. 운영 및 유지보수 (Operations and Maintenance):
오타 수정 시스템을 운영하며, 주기적인 유지보수 및 업데이트를 수행합니다. 신조어 및 유행어의 변화를 계속 모니터링하고 시스템을 업데이트하여 최신 유행어에 대응합니다.

## 6. Budget

- Provide a financial plan covering hardware, software, labor, and other costs.
- Include a contingency plan for unexpected expenses.

학교의 클라우드 서버 활용 계획입니다. 한국어 LLM의 크기가 평균적으로 1TB이사 이므로 데이터는 분산하여 관리할 계획입니다.

## 7. System Architecture

데이터 스토리지: 시스템의 핵심 부분은 데이터 스토리지입니다. 우리는 대용량 데이터를 저장하고 관리하기 위해 분산형 데이터베이스를 선택했습니다. 이 데이터베이스는 데이터를 안전하게 보관하고 검색 가능하게 만들어줍니다.

데이터 관리 전략: 데이터의 수명주기를 관리하기 위해 데이터 유효기간, 보안 정책 및 데이터 백업 절차를 정의했습니다. 데이터 일관성과 무결성을 유지하기 위해 정기적인 데이터 정리 및 유지보수를 수행합니다.

하드웨어: 서버 클러스터와 고성능 스토리지 장치를 사용하여 데이터 처리와 저장을 지원합니다. 네트워크 장비는 높은 대역폭을 제공하여 데이터 전송을 원활하게 합니다. 이를 위해 학교 서버를 활용할 계획입니다.

데이터 분석: 데이터 분석을 위해 Python 프로그래밍 언어를 사용하며, Jupyter Notebook과 같은 환경에서 데이터 분석 작업을 수행합니다. 데이터 분석 결과는 대시보드와 연동하여 실시간으로 업데이트됩니다.

## 8. Risks Assessment

- **기술적인 문제:** NLP 모델의 학습 및 실행에 필요한 컴퓨팅 리소스 부족
    - **완화 전략:** 클라우드 컴퓨팅 서비스를 활용하여 필요한 리소스를 동적으로 할당하고, 스케일링 옵션을 구성하여 대처합니다.
- **데이터 부족:** 2000년대 초의 데이터 양이 한정적일 수 있음
    - **완화 전략:** 데이터 증식 및 데이터 강화 기술을 사용하여 학습 데이터를 보강합니다.
- **유행어와 신조어 변화:** 현재 유행어와 신조어가 빠르게 변하므로 시스템이 이에 대응하기 어려울 수 있음
    - **완화 전략:** 실시간 크롤링을 통해 최신 데이터를 수집하고 모델을 주기적으로 업데이트합니다.
- **보안 문제:** 개인 정보가 포함된 데이터를 다룰 경우, 데이터 보안 문제 발생 가능성
    - **완화 전략:** 데이터 암호화, 접근 제어 및 규정 준수를 위한 보안 프로토콜을 구현하여 데이터 보안을 강화합니다.

## 9. Resources

- **장비:** 학교 서버
- **소프트웨어:** Python, TensorFlow 또는 PyTorch (딥러닝 모델 개발), 웹 크롤링 도구 (Scrapy)

# 10. Technical Specifications

- **데이터 원본:** 2000년대 초와 현재의 웹 콘텐츠, 유튜브 채널 및 댓글, 인스타그램 댓글 데이터
- **데이터 변환:** 텍스트 데이터의 토큰화, 불용어 제거, 형태소 분석
- **알고리즘:** 딥러닝 모델 (예: LSTM, Transformer)을 사용한 NLP 모델
- **기술 스택:** Python, TensorFlow 또는 PyTorch, Scrapy

## 11. Timeline and Deliverables

- **프로젝트 타임라인:**
    - 계획 단계: 1주
    - 분석 단계: 1주
    - 설계 단계: 1주
    - 구현 단계: 4주
    - 테스트 단계: 2주
    - 배포 단계: 1주
    - 유지보수 단계: 지속적으로 반복
- **마일스톤과 결과물:**
    - 마일스톤 1: 학습 데이터 수집 및 전처리 완료
    - 마일스톤 2: NLP 모델 개발 및 테스트 완료
    - 마일스톤 3: 시스템 구현 및 테스트 완료
    - 마일스톤 4: 오타 수정 시스템 배포
    - 마일스톤 5: 실시간 크롤링 및 모델 업데이트 구현
    - 품질 보증 조치: 모델의 정확도, 재현율, 정밀도를 모니터링하고 지속적으로 개선

## 12. Conclusion

- 이 프로젝트는 2000년대 초와 현재의 유행어와 신조어를 오타 수정 시스템에 적용하는 중요한 과제로, 현대 텍스트의 품질을 향상시킬 것입니다.
- 잠재적인 문제를 인식하고, 데이터 부족 및 보안 문제와 같은 위험을 감소시키기 위한 적절한 전략을 마련했습니다.
- 품질 보증 조치와 지속적인 유지보수를 통해 프로젝트 성공을 보장하며, 오타 수정 시스템을 사용자에게 제공하여 온라인 텍스트의 품질을 향상시킬 것입니다.
