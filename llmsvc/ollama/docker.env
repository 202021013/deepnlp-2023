OLLAMA_GPU_DEVICE_ID=3
OLLAMA_WORKSPACE_ROOT="$PWD/workspace/ollama"
OLLAMA_SVC_PORT=11434
OLLAMA_CONTAINER_NAME="ollama"
OLLAMA_MODEL_NAME="llama2:13b"
#########################################################
# Configuration parameters for the docker project       #
# Change the variables below to your need:              #
#########################################################
DOCKER_PROJECT_NAME=${PROJECT_NAME:-"ollama"}                  # The name of the Docker project
IMAGE_TAG="latest"                                             # The tag of the Docker image
IMAGE_NAME="ollama/ollama"                                     # The full name of the Docker image
CONTAINER_HOSTNAME="${DOCKER_PROJECT_NAME}-server"             # The hostname of the Docker container
CONTAINER_HF_TOKEN=${HF_TOKEN:-""}                             # The Hugging Face token to use in the container
CONTAINER_WEB_SVC_PORT=${OLLAMA_SVC_PORT:-"11434"}             # The Web service port in the Docker container
HOST_WEB_SVC_PORT=${OLLAMA_SVC_PORT-"11434"}                   # The Web service port on the host machine to be mapped to the container's Web service port
CONTAINER_IPC=${CONTAINER_IPC:-"host"}                         # The IPC mode for the Docker container
CONTAINER_CUDA_DEVICE_ID=${CONTAINER_CUDA_DEVICE_ID:-"3"}      # The ID of the CUDA device to use, e.g. all, 0, 1, 2, etc.
MODEL_NAME=${OLLAMA_MODEL_NAME:-"llama2"}                      # The name of the model to use
CONTAINER_HF_HOME="/root/.cache/huggingface"                   # HuggingFace models cache directory
HOST_HF_HOME="${PWD}/workspace/huggingface"                    # Host path for HuggingFace models cache
CONTAINER_WORKSPACE_ROOT="/root/.ollama"                       # The path to the workspace directory inside the container
HOST_WORKSPACE_ROOT=${OLLAMA_WORKSPACE_ROOT:-"$PWD/workspace"} # The path to the workspace directory on the host machine that will be mapped to the container's workspace directory
